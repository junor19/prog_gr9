{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b256afce",
   "metadata": {},
   "source": [
    "**Gå tilbake til [← innledningen](miljoanalyseprosjekt.ipynb) eller [del 2 →](del2.ipynb) av prosjektet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3e1f3",
   "metadata": {},
   "source": [
    "## **Del 1**\n",
    "\n",
    "I dette prosjektet skal vi gjennomføre oppgaver som fokuserer på oppsett av utviklingsmiljø, innsamling, behandling, analyse, visualisering og prediktiv analyse av miljødata. Oppgave 1 handler om å sette opp et fungerende utviklingsmiljø. Oppgave 2 innebærer å identifisere relevante åpne datakilder og implementere funksjonalitet for å hente data fra disse kildene ved hjelp av Python. I oppgave 3 skal vi utvikle funksjoner for å rense og formatere de innsamlede dataene, med fokus på håndtering av manglende verdier.\n",
    "\n",
    "Kode nødvendig for å kunne hente funksjoner senere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d3b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd644d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Oppgave 1: Sett opp utviklingsmiljø**\n",
    "\n",
    "I VSCode, opprett en ny Jupyter Notebook-fil (med filendelsen «.ipynb») i prosjektmappen. Skriv og kjør kode i den første cellen for å teste at miljøet fungerer som det skal:\n",
    "\n",
    "Gå til [oppgave 1](oppg1.ipynb) \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9c533",
   "metadata": {},
   "source": [
    "## **Oppgave 2: Datainnsamling**\n",
    "\n",
    "### Hvorfor MET?\n",
    "For dette prosjektet ønsket vi å se på litt ukonvesjonelle data, så vi valgte derfor å se på solskinn varighet. Solskinn kan indikere endringer i skydekke og værmønstre. Det kan også fortelle oss noe om hvor mye solenergi som når bakken som vil påvirke lokal tempratur og som videre kan spille inn på oppvarmingstrender. Spesielt utvikling over tid vil være interessant. \n",
    "\n",
    "Før vi bestemte oss for å undersøke sollys var vi først inne å gjode oss kjent med ulike API grensesnitt. Den som sto fram som et godt valg var **The MET weather API**, mer spesefikt valgte vi **Frost API-en** deres. Denne gir gratis tilgang til deres arkiv over historiske vær- og klimadata av stor variasjon og med mye detaljer av kvalitetskontrollerte målinger. \n",
    "\n",
    "Les mer her [Hva er Frost?](https://frost.met.no/index.html) og [Om Meteorologisk Institutt](https://www.met.no/en/About-us/About-MET-Norway)\n",
    "\n",
    "De har en fri og åpen data politikk, med ønske om at dataen de samler kan bli brukt fritt til fordel for samfunnet. Deres kontaktinformasjon, til og med en egen nettside [hvordan komme hit](https://www.met.no/en/contact-us/travel-here) er et godt tegn på legitimitet ettersom de er lett å komme i kontakt med. Det er et statlig etat, med formål om å informere med veldokumentert forsking samt nøytralt og saklig språk. Nettsiden er utformet på en overskitlig og profesjonell måte med mange forklaringer, oppslagsverk og dataklarifikasjoner som gjør forståelse og henting av data letter. \n",
    "\n",
    "### Hvorfor CSV-fil?\n",
    "\n",
    "Frost API bruker JSON-format til data, vi valgte å gjør om og lagre i CSV-fil ettersom det er standard for de fleste analyseverktøy og fungerer for eksempel bra med Pandas, Matplotlib og Plotly. Det er også raskt å laste inn og veldig lesbart. \n",
    "\n",
    "Dataen er strukturert slik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0471092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       date  sunshine_hours\n",
      "0  2016-01-01T00:00:00.000Z             0.9\n",
      "1  2016-01-02T00:00:00.000Z             1.3\n",
      "2  2016-01-03T00:00:00.000Z             3.5\n",
      "3  2016-01-04T00:00:00.000Z             3.6\n",
      "4  2016-01-05T00:00:00.000Z             2.8\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raa_data_d.csv\", nrows=5)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe9dc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Oppgave 3: Databehandling**\n",
    "\n",
    "Her skal vi fokusere på databehandling ved å utvikle funksjoner som renser og formaterer de innsamlede dataene, med særlig vekt på håndtering av manglende verdier og uregelmessigheter ved hjelp av Pandas. I tillegg skal vi benytte teknikker som list comprehensions, iteratorer, pandas og pandas sql (sqldf) for å manipulere dataene effektivt, noe som vil bidra til å forberede dataene for videre analyse.\n",
    "\n",
    "### Hvilke endringer har vi gjort?\n",
    "\n",
    "Datasettet vi hentet fra MET var av høy kvalitet uten hull så vi valgte å fjerne og dyplisere data for å igjen kunne gjennopprette disse dataene med estimasjon.\n",
    "\n",
    "Her er en oversikt over dataen som ble fjernet og duplisert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a09d50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antall totale rader i datasettet: 1819\n",
      "antall dupliserte datoer: 8\n",
      "antall datoer som mangler: 16\n",
      "\n",
      "Dupliserte datoer:\n",
      "799   2018-03-19 00:00:00+00:00\n",
      "801   2018-03-20 00:00:00+00:00\n",
      "803   2018-03-21 00:00:00+00:00\n",
      "805   2018-03-22 00:00:00+00:00\n",
      "807   2018-03-23 00:00:00+00:00\n",
      "809   2018-03-24 00:00:00+00:00\n",
      "811   2018-03-25 00:00:00+00:00\n",
      "813   2018-03-26 00:00:00+00:00\n",
      "Name: date, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Manglende datoer:\n",
      "['2016-10-01', '2016-10-02', '2016-10-03', '2017-07-18', '2017-07-19', '2017-07-20', '2017-07-21', '2017-07-22', '2017-07-23', '2017-07-24', '2019-12-25', '2019-12-26', '2019-12-27', '2019-12-28', '2019-12-29', '2019-12-30']\n"
     ]
    }
   ],
   "source": [
    "from src.finne_mangler import finne_hull\n",
    "\n",
    "filbane = \"../data/raa_data_d.csv\"\n",
    "duplikater, hull = finne_hull(filbane, dato_kolonne=\"date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6430a94",
   "metadata": {},
   "source": [
    "### Håndtere feil\n",
    "\n",
    "Vi benytter så **vasket_data** funksjonen for videre kunne fylle disse hullene og fjerne duplikatene, vi valgte lineær interpolasjon som metode her.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc369a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antall totale rader i datasettet: 1819\n",
      "antall dupliserte datoer: 8\n",
      "antall datoer som mangler: 16\n",
      "\n",
      "Dupliserte datoer:\n",
      "799   2018-03-19 00:00:00+00:00\n",
      "801   2018-03-20 00:00:00+00:00\n",
      "803   2018-03-21 00:00:00+00:00\n",
      "805   2018-03-22 00:00:00+00:00\n",
      "807   2018-03-23 00:00:00+00:00\n",
      "809   2018-03-24 00:00:00+00:00\n",
      "811   2018-03-25 00:00:00+00:00\n",
      "813   2018-03-26 00:00:00+00:00\n",
      "Name: date, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Manglende datoer:\n",
      "['2016-10-01', '2016-10-02', '2016-10-03', '2017-07-18', '2017-07-19', '2017-07-20', '2017-07-21', '2017-07-22', '2017-07-23', '2017-07-24', '2019-12-25', '2019-12-26', '2019-12-27', '2019-12-28', '2019-12-29', '2019-12-30']\n",
      "\n",
      "Benyttet lineær interpolasjon, fil lagret som : utfylt_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\junoh\\Documents\\1 DigFor\\2 semester\\4114 anvendt programering\\prog_gr9\\proj_environment-main\\src\\finne_mangler.py:62: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_utfylt = pd.concat([df, df_manglende], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sunshine_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00+00:00</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02 00:00:00+00:00</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03 00:00:00+00:00</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04 00:00:00+00:00</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05 00:00:00+00:00</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2020-12-27 00:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2020-12-28 00:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2020-12-29 00:00:00+00:00</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2020-12-30 00:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>2020-12-31 00:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1827 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  sunshine_hours\n",
       "0    2016-01-01 00:00:00+00:00             0.9\n",
       "1    2016-01-02 00:00:00+00:00             1.3\n",
       "2    2016-01-03 00:00:00+00:00             3.5\n",
       "3    2016-01-04 00:00:00+00:00             3.6\n",
       "4    2016-01-05 00:00:00+00:00             2.8\n",
       "...                        ...             ...\n",
       "1822 2020-12-27 00:00:00+00:00             0.0\n",
       "1823 2020-12-28 00:00:00+00:00             0.0\n",
       "1824 2020-12-29 00:00:00+00:00             0.6\n",
       "1825 2020-12-30 00:00:00+00:00             0.0\n",
       "1826 2020-12-31 00:00:00+00:00             0.0\n",
       "\n",
       "[1827 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.finne_mangler import vasket_data\n",
    "vasket_data(\"../data/raa_data_d.csv\", dato_kolonne=\"date\", output_fil=\"utfylt_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54acb50b",
   "metadata": {},
   "source": [
    "### Forklaring \n",
    "\n",
    "Manglene og uregelmessighetene vi forventet å møte var:\n",
    "1. manglende datoer\n",
    "2. duplikerte datoer\n",
    "3. manglende verider i målingene (NaN)\n",
    "4. feilformaterte datoer\n",
    "\n",
    "For å håndtere 1. feil lagde vi funksjonene finne_hull(), mer spesifikt brukte vi pandas pd.date_range() for å finne hvilke datoer det gjelder for å så fyller hullene ved metoden interpolasjon i funksjonen vasket_data().\n",
    "\n",
    "For å fjerne duplikater datoer brukte vi drop_duplicates().\n",
    "\n",
    "Manglende målinger blir plukket opp ved hjelp av en løkke hvor alle verdiene får en type middlertidig \"missing value\" for senere å interpolere dem.\n",
    "\n",
    "For datoer som kan være i feil format eller tekst brukte vi pd.to_datetime() for å standarisere formatet. \n",
    "\n",
    "\n",
    "### Pandas SQL\n",
    "\n",
    "Med sqldf er det mulig å bruke SQL-spørringer på Pandas DataFrames. Altså kan man gjennomføre komplekse joins, grupperinger og filtreretinger på en veldig lesbar måte. Dette vil være en intuitiv måte å jobbe med dataen på om man er kjent med SQL fra før.\n",
    "\n",
    "les mer her [using SQL with Pandas DataFrames](https://medium.com/@davidfagb/using-sql-with-pandas-dataframes-1c36f57ea65d)\n",
    "\n",
    "### List comperhensions\n",
    "En måte å manipulere data er ved hjelp av list comprehensions, for eksempel konvertere vi DateTimeIndex-en for manglende dato fra finne_hull() som gjorde datoene mer lesbar som 'YYYY-MM-DD'\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc4382e",
   "metadata": {},
   "source": [
    "## **Litteraturliste**\n",
    "*About the Norwegian Meteorological Institute.* (2017, October 2). Www.met.no; Meteorologisk Institutt. https://www.met.no/en/About-us/About-MET-Norway\n",
    "\n",
    "Bhargawa, A., & Singh, A. K. (2019). Solar irradiance, climatic indicators and climate change – An empirical analysis. *Advances in Space Research*, 64(1), 271–277. https://doi.org/10.1016/j.asr.2019.03.018\n",
    "\n",
    "Fagbuyiro, D. (2023, October 17). *Using SQL with Pandas DataFrames.* Medium. https://medium.com/@davidfagb/using-sql-with-pandas-dataframes-1c36f57ea65d\n",
    "\n",
    "Geeksforgeeks. (n.d.-a). *Geeksforgeeks linechart in Matplotlib-Python.* www.Geeksforgeeks.org. https://www.geeksforgeeks.org/line-chart-in-matplotlib-python/\n",
    "\n",
    "Haigh, J. (2011). *Solar influences on Climate.* Imperial Collage London . https://www.imperial.ac.uk/media/imperial-college/grantham-institute/public/publications/briefing-papers/Solar-Influences-on-Climate---Grantham-BP-5.pdf?utm\n",
    "\n",
    "Matplotlib. (n.d.-a). *matplotlib Plotting categorical variables.* www.matplotlib.org. https://matplotlib.org/stable/gallery/lines_bars_and_markers/categorical_variables.html#sphx-glr-gallery-lines-bars-and-markers-categorical-variables-py\n",
    "\n",
    "Matplotlib. (n.d.-a). *Matplotlib constrained layout quide.* www.matplotlib.org. https://matplotlib.org/stable/users/explain/axes/constrainedlayout_guide.html\n",
    "\n",
    "Python. (n.d.-a). *Python unittest.* www.python.org. https://docs.python.org/3/library/unittest.html\n",
    "\n",
    "Python. (n.d.-a). *python linechart.* www.python.org https://python-graph-gallery.com/line-chart/\n",
    "\n",
    "Rouhani, M. (2019). *Applied Programming — Applied Programming.* Ntnu.no. https://rouhani.folk.ntnu.no/textbooks/tdt4114/intro.html\n",
    "\n",
    "Vilius Dumcius. (2024, November 5). *JSON vs CSV: What’s the Difference?* IPRoyal.com; IPRoyal. https://iproyal.com/blog/json-vs-csv/\n",
    "\n",
    "W3Schools. (n.d.-a). *Pandas median, gjennomsnitt, standardavvik.* www.w3school.com. https://www.w3schools.com/python/pandas/ref_df_median.asp\n",
    "\n",
    "W3Schools. (n.d.-a). *Pandas - Removing Duplicates.* Www.w3schools.com. https://www.w3schools.com/python/pandas/pandas_cleaning_duplicates.asp\n",
    "\n",
    "W3Schools. (n.d.-b). *Pandas DataFrames.* Www.w3schools.com. https://www.w3schools.com/python/pandas/pandas_dataframes.asp\n",
    "\n",
    "*What is Frost?* (2019). Frost.met.no; Meteorologisk Institutt. https://frost.met.no/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b8beb",
   "metadata": {},
   "source": [
    "**Gå tilbake til [← innledningen](miljoanalyseprosjekt.ipynb) eller [del 2 →](del2.ipynb) av prosjektet**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
